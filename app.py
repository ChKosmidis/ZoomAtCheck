import streamlit as st
import pandas as pd
import re
import difflib

# --- –§–£–ù–ö–¶–ò–ò –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò ---

def clean_text(text):
    if not isinstance(text, str):
        return ""
    return re.sub(r'\W+', ' ', text).lower().strip()

def get_tokens(text):
    return set(clean_text(text).split())

def strict_clean(text):
    return re.sub(r'\W+', '', str(text)).lower()

def process_files(df_signup, df_attendance, threshold_minutes):
    # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    signup_col = df_signup.columns[0]
    att_name_col = df_attendance.columns[0]
    att_dur_col = df_attendance.columns[1]

    # –ü–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫
    for col in df_attendance.columns:
        if "–ò–º—è" in col: att_name_col = col
        if "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å" in col: att_dur_col = col

    signup_names = df_signup[signup_col].dropna().unique()
    
    # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –º–∞—Ç—á–∏–Ω–≥–∞
    signup_specs = []
    for name in signup_names:
        c_name = clean_text(name)
        tokens = get_tokens(name)
        signup_specs.append({
            'original': name, 
            'tokens': tokens,
        })

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–º–µ–Ω–∏
    df_attendance['normalized_name'] = None

    # --- –≠–¢–ê–ü 1: –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –∏ —Ç–æ–∫–µ–Ω—ã ---
    for idx, row in df_attendance.iterrows():
        att_name_raw = row[att_name_col]
        att_tokens = get_tokens(att_name_raw)
        
        best_match = None
        best_score = 0
        
        for spec in signup_specs:
            s_tokens = spec['tokens']
            if not s_tokens or not att_tokens:
                continue
            
            common = s_tokens.intersection(att_tokens)
            score = len(common)
            is_subset = s_tokens.issubset(att_tokens) or att_tokens.issubset(s_tokens)
            
            if score >= 2:
                if score > best_score:
                    best_score = score
                    best_match = spec['original']
            elif score == 1 and is_subset and (len(s_tokens) == 1 or len(att_tokens) == 1):
                 if score > best_score:
                    best_score = score
                    best_match = spec['original']

        if best_match:
            df_attendance.at[idx, 'normalized_name'] = best_match

    # --- –≠–¢–ê–ü 2: Fuzzy Matching ---
    found_names = set(df_attendance['normalized_name'].dropna().unique())
    missing_signup_names = [n for n in signup_names if n not in found_names]
    
    missing_signup_map = {strict_clean(name): name for name in missing_signup_names}
    missing_keys = list(missing_signup_map.keys())

    unmatched_indices = df_attendance[df_attendance['normalized_name'].isnull()].index
    
    for idx in unmatched_indices:
        att_raw = df_attendance.at[idx, att_name_col]
        att_clean = strict_clean(att_raw)
        matches = difflib.get_close_matches(att_clean, missing_keys, n=1, cutoff=0.6)
        
        if matches:
            matched_key = matches[0]
            df_attendance.at[idx, 'normalized_name'] = missing_signup_map[matched_key]

    # --- –†–ê–°–ß–ï–¢ –°–¢–ê–¢–ò–°–¢–ò–ö–ò ---
    duration_stats = df_attendance.groupby('normalized_name')[att_dur_col].sum().reset_index()
    
    present_names = set(duration_stats['normalized_name'])
    all_signup = set(signup_names)
    
    # –°–ø–∏—Å–æ–∫ 1: –ù–µ –±—ã–ª–∏
    not_present = sorted(list(all_signup - present_names))
    
    # –°–ø–∏—Å–æ–∫ 2: –ë—ã–ª–∏ –º–µ–Ω—å—à–µ threshold_minutes
    under_threshold = duration_stats[duration_stats[att_dur_col] < threshold_minutes].sort_values('normalized_name')
    under_threshold_list = under_threshold[['normalized_name', att_dur_col]].values.tolist()

    return not_present, under_threshold_list, df_attendance

# --- –ò–ù–¢–ï–†–§–ï–ô–° ---

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–µ—â–∞–µ–º–æ—Å—Ç–∏", layout="wide")

st.title("üìä –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–µ—â–∞–µ–º–æ—Å—Ç–∏ Zoom")

# –ë–ª–æ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫
with st.container():
    st.write("### 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—Ä–µ–º–µ–Ω–∏")
    col_opt, col_val = st.columns([1, 2])
    
    with col_opt:
        # –†–∞–¥–∏–æ–∫–Ω–æ–ø–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ä–µ–∂–∏–º–∞
        time_mode = st.radio(
            "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è:",
            options=["90 –º–∏–Ω—É—Ç", "60 –º–∏–Ω—É—Ç", "–î—Ä—É–≥–æ–µ"],
            horizontal=False
        )
    
    with col_val:
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è threshold
        if time_mode == "90 –º–∏–Ω—É—Ç":
            threshold = 90
            st.info(f"–í—ã–±—Ä–∞–Ω –ø–æ—Ä–æ–≥: **{threshold} –º–∏–Ω**")
        elif time_mode == "60 –º–∏–Ω—É—Ç":
            threshold = 60
            st.info(f"–í—ã–±—Ä–∞–Ω –ø–æ—Ä–æ–≥: **{threshold} –º–∏–Ω**")
        else:
            threshold = st.number_input("–í–≤–µ–¥–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∏–Ω—É—Ç:", min_value=1, value=45, step=5)
            st.warning(f"–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ä—É—á–Ω–æ–π –ø–æ—Ä–æ–≥: **{threshold} –º–∏–Ω**")

st.divider()

st.write("### 2. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
col1, col2 = st.columns(2)

with col1:
    file_signup = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å '–ó–∞–ø–∏—Å–∞–ª–∏—Å—å' (.csv)", type=['csv'])

with col2:
    file_attendance = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å '–ü–æ—Å–µ—â–∞–µ–º–æ—Å—Ç—å' (.csv)", type=['csv'])

if file_signup and file_attendance:
    st.divider()
    
    try:
        # –ß—Ç–µ–Ω–∏–µ —Å –∞–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
        try:
            df_s = pd.read_csv(file_signup)
            if df_s.shape[1] < 1: df_s = pd.read_csv(file_signup, sep=';')
        except:
             st.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –∑–∞–ø–∏—Å–∏.")
        
        try:
            df_a = pd.read_csv(file_attendance, sep=';')
            if df_a.shape[1] < 2: df_a = pd.read_csv(file_attendance, sep=',')
        except:
             st.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø–æ—Å–µ—â–∞–µ–º–æ—Å—Ç–∏.")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å —É—á–µ—Ç–æ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ threshold
        not_present, under_threshold, df_debug = process_files(df_s, df_a, threshold)
        
        st.success("–ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∏–∂–µ.")
        
        res_col1, res_col2 = st.columns(2)
        
        with res_col1:
            st.subheader(f"üî¥ –ó–∞–ø–∏—Å–∞–ª–∏—Å—å, –Ω–æ –Ω–µ –ø—Ä–∏—à–ª–∏ ({len(not_present)})")
            df_not = pd.DataFrame(not_present, columns=["–ò–º—è"])
            st.dataframe(df_not, use_container_width=True, height=400)
            
            st.download_button(
                "–°–∫–∞—á–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö",
                data=df_not.to_csv(index=False).encode('utf-8'),
                file_name="–Ω–µ_–ø—Ä–∏—à–ª–∏.csv",
                mime="text/csv"
            )

        with res_col2:
            st.subheader(f"üü° –ë—ã–ª–∏ –º–µ–Ω–µ–µ {threshold} –º–∏–Ω—É—Ç ({len(under_threshold)})")
            df_under = pd.DataFrame(under_threshold, columns=["–ò–º—è", "–í—Ä–µ–º—è (–º–∏–Ω)"])
            st.dataframe(df_under, use_container_width=True, height=400)
            
            st.download_button(
                f"–°–∫–∞—á–∞—Ç—å —Å–ø–∏—Å–æ–∫ (<{threshold} –º–∏–Ω)",
                data=df_under.to_csv(index=False).encode('utf-8'),
                file_name=f"–º–µ–Ω–µ–µ_{threshold}_–º–∏–Ω—É—Ç.csv",
                mime="text/csv"
            )
            
        with st.expander("üîé –î–µ—Ç–∞–ª–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–º–µ–Ω"):
             st.dataframe(df_debug[['–ò–º—è (–ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –∏–º—è)', 'normalized_name', df_debug.columns[1]]].dropna())

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞: {e}")